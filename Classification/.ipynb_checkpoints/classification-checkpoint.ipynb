{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d6c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    roc_curve,\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Optional gradient boosting libraries (guarded imports)\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception as e:\n",
    "    lgb = None\n",
    "    print(\"LightGBM not available:\", e)\n",
    "\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception as e:\n",
    "    xgb = None\n",
    "    print(\"XGBoost not available:\", e)\n",
    "\n",
    "try:\n",
    "    import catboost as cbt\n",
    "except Exception as e:\n",
    "    cbt = None\n",
    "    print(\"CatBoost not available:\", e)\n",
    "\n",
    "np.random.seed(42)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a5bfd",
   "metadata": {},
   "source": [
    "## Data Loading and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264b0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"adult.csv\")\n",
    "\n",
    "# Basic info\n",
    "print(\"Dataset Shape:\", data.shape)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(data.info())\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values (including '?' which is common in Adult dataset)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Missing Values:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Checking for '?' values:\")\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    question_marks = (data[col] == '?').sum()\n",
    "    if question_marks > 0:\n",
    "        print(f\"{col}: {question_marks} '?' values\")\n",
    "\n",
    "# Distribution of target variable\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Income Distribution:\")\n",
    "print(data[\"income\"].value_counts())\n",
    "print(\"\\nIncome Proportions:\")\n",
    "print(data[\"income\"].value_counts(normalize=True))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "data[\"income\"].value_counts().plot(kind=\"bar\", color=['skyblue', 'orange'])\n",
    "plt.title(\"Distribution of Income Classes\")\n",
    "plt.xlabel(\"Income\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_numeric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numeric features\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"Numeric columns ({len(numeric_cols)}): {numeric_cols}\")\n",
    "\n",
    "# Distribution of numeric features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    if i < len(axes):\n",
    "        sns.histplot(data[col], kde=True, ax=axes[i], color='steelblue')\n",
    "        axes[i].set_title(f\"Distribution of {col}\")\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel(\"Frequency\")\n",
    "\n",
    "# Remove empty subplots\n",
    "for j in range(len(numeric_cols), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap for numeric columns\n",
    "plt.figure(figsize=(10, 8))\n",
    "corr_matrix = data[numeric_cols].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", center=0, fmt=\".2f\", square=True)\n",
    "plt.title(\"Correlation Matrix of Numerical Features\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_age_hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age distribution by income\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=\"income\", y=\"age\", data=data, palette=\"Set2\")\n",
    "plt.title(\"Age Distribution by Income\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Hours per week by income\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=\"income\", y=\"hours.per.week\", data=data, palette=\"Set2\")\n",
    "plt.title(\"Hours per Week Distribution by Income\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Education years by income\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x=\"income\", y=\"education.num\", data=data, palette=\"Set2\")\n",
    "plt.title(\"Education Years Distribution by Income\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_categorical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze categorical features vs target\n",
    "categorical_cols = data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "categorical_cols.remove(\"income\")  # Remove target\n",
    "\n",
    "print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "\n",
    "# Plot key categorical features\n",
    "key_cats = [\"workclass\", \"education\", \"marital.status\", \"occupation\", \"sex\", \"race\"]\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(key_cats):\n",
    "    if col in data.columns and i < len(axes):\n",
    "        # Filter out '?' values for better visualization\n",
    "        data_filtered = data[data[col] != '?']\n",
    "        pd.crosstab(data_filtered[col], data_filtered[\"income\"], normalize=\"index\").plot(\n",
    "            kind=\"bar\", stacked=True, ax=axes[i], color=['skyblue', 'orange']\n",
    "        )\n",
    "        axes[i].set_title(f\"Income distribution by {col}\")\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel(\"Proportion\")\n",
    "        axes[i].legend(title=\"Income\", loc='best')\n",
    "        axes[i].tick_params(axis=\"x\", rotation=45, labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146c9373",
   "metadata": {},
   "source": [
    "## Data Descriptions\n",
    "\n",
    "The **Adult Dataset** (also known as Census Income dataset) is used to predict whether a person's income exceeds $50K/year based on census data.\n",
    "\n",
    "**Features:**\n",
    "- **age** — Age in years (continuous)\n",
    "- **workclass** — Type of employer (Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked)\n",
    "- **fnlwgt** — Final weight (sampling weight representing the number of people the census believes this entry represents)\n",
    "- **education** — Highest level of education achieved (Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool)\n",
    "- **education.num** — Numerical encoding of education level (continuous)\n",
    "- **marital.status** — Marital status (Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse)\n",
    "- **occupation** — Type of occupation (Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces)\n",
    "- **relationship** — Relationship status (Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried)\n",
    "- **race** — Race (White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black)\n",
    "- **sex** — Gender (Female, Male)\n",
    "- **capital.gain** — Capital gains (continuous)\n",
    "- **capital.loss** — Capital losses (continuous)\n",
    "- **hours.per.week** — Hours worked per week (continuous)\n",
    "- **native.country** — Country of origin (United-States, Cambodia, England, etc.)\n",
    "\n",
    "**Target Variable:**\n",
    "- **income** — Income class (<=50K, >50K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8e8af",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8870b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Replace '?' with NaN\n",
    "    df = df.replace('?', np.nan)\n",
    "    \n",
    "    # Handle missing values: median for numeric, mode for categorical\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype != \"object\":\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "        else:\n",
    "            df[col] = df[col].fillna(df[col].mode()[0] if not df[col].mode().empty else \"None\")\n",
    "    \n",
    "    # Encode categorical variables using LabelEncoder\n",
    "    # NOTE: For production, OneHotEncoder is typically better.\n",
    "    for col in df.select_dtypes(include=[\"object\"]).columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(\"income\", axis=1)\n",
    "y = data[\"income\"]\n",
    "\n",
    "# Encode target: <=50K -> 0, >50K -> 1\n",
    "le_target = LabelEncoder()\n",
    "y = le_target.fit_transform(y)\n",
    "\n",
    "print(f\"Target classes: {le_target.classes_}\")\n",
    "print(f\"Target encoding: {dict(zip(le_target.classes_, le_target.transform(le_target.classes_)))}\")\n",
    "print(f\"\\nClass distribution in encoded target:\")\n",
    "print(pd.Series(y).value_counts().sort_index())\n",
    "\n",
    "# Preprocess features\n",
    "X_processed = preprocess_data(X)\n",
    "\n",
    "# Split data into train and test sets (80-20 split with stratification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nProcessed shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "print(f\"\\nFeatures: {list(X_processed.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e76979",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bd5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    train_pred = model.predict(X_train)\n",
    "    test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Get prediction probabilities if available\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "        test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        train_pred_proba = None\n",
    "        test_pred_proba = None\n",
    "\n",
    "    # Calculate metrics\n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    train_precision = precision_score(y_train, train_pred)\n",
    "    train_recall = recall_score(y_train, train_pred)\n",
    "    train_f1 = f1_score(y_train, train_pred)\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_precision = precision_score(y_test, test_pred)\n",
    "    test_recall = recall_score(y_test, test_pred)\n",
    "    test_f1 = f1_score(y_test, test_pred)\n",
    "    \n",
    "    if train_pred_proba is not None and test_pred_proba is not None:\n",
    "        train_auc = roc_auc_score(y_train, train_pred_proba)\n",
    "        test_auc = roc_auc_score(y_test, test_pred_proba)\n",
    "    else:\n",
    "        train_auc = None\n",
    "        test_auc = None\n",
    "\n",
    "    print(f\"{model_name} Results:\")\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Train Precision: {train_precision:.4f}\")\n",
    "    print(f\"Train Recall: {train_recall:.4f}\")\n",
    "    print(f\"Train F1 Score: {train_f1:.4f}\")\n",
    "    if train_auc is not None:\n",
    "        print(f\"Train AUC-ROC: {train_auc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {test_precision:.4f}\")\n",
    "    print(f\"Test Recall: {test_recall:.4f}\")\n",
    "    print(f\"Test F1 Score: {test_f1:.4f}\")\n",
    "    if test_auc is not None:\n",
    "        print(f\"Test AUC-ROC: {test_auc:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return model, (y_train, train_pred, y_test, test_pred, train_pred_proba, test_pred_proba)\n",
    "\n",
    "# Train baseline models\n",
    "baseline_models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "baseline_results = {}\n",
    "for name, model in baseline_models.items():\n",
    "    baseline_results[name] = train_and_evaluate(\n",
    "        model, X_train_scaled, y_train, X_test_scaled, y_test, name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced_models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train advanced models\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "rf_trained, rf_results = train_and_evaluate(\n",
    "    rf_model, X_train, y_train, X_test, y_test, \"Random Forest\"\n",
    ")\n",
    "\n",
    "if lgb is not None:\n",
    "    lgb_model = lgb.LGBMClassifier(random_state=42, n_jobs=-1, verbosity=-1)\n",
    "    lgb_trained, lgb_results = train_and_evaluate(\n",
    "        lgb_model, X_train, y_train, X_test, y_test, \"LightGBM\"\n",
    "    )\n",
    "else:\n",
    "    lgb_trained, lgb_results = None, None\n",
    "\n",
    "if xgb is not None:\n",
    "    xgb_model = xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss')\n",
    "    xgb_trained, xgb_results = train_and_evaluate(\n",
    "        xgb_model, X_train, y_train, X_test, y_test, \"XGBoost\"\n",
    "    )\n",
    "else:\n",
    "    xgb_trained, xgb_results = None, None\n",
    "\n",
    "if cbt is not None:\n",
    "    cbt_model = cbt.CatBoostClassifier(random_state=42, verbose=False)\n",
    "    cbt_trained, cbt_results = train_and_evaluate(\n",
    "        cbt_model, X_train, y_train, X_test, y_test, \"CatBoost\"\n",
    "    )\n",
    "else:\n",
    "    cbt_trained, cbt_results = None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bc3be8",
   "metadata": {},
   "source": [
    "## Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confusion_matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "                xticklabels=le_target.classes_, yticklabels=le_target.classes_)\n",
    "    plt.title(f\"Confusion Matrix - {model_name}\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices for all models\n",
    "for name, (model, results) in baseline_results.items():\n",
    "    y_train, train_pred, y_test, test_pred, _, _ = results\n",
    "    plot_confusion_matrix(y_test, test_pred, name)\n",
    "\n",
    "if rf_results:\n",
    "    plot_confusion_matrix(rf_results[2], rf_results[3], \"Random Forest\")\n",
    "\n",
    "if lgb_results:\n",
    "    plot_confusion_matrix(lgb_results[2], lgb_results[3], \"LightGBM\")\n",
    "\n",
    "if xgb_results:\n",
    "    plot_confusion_matrix(xgb_results[2], xgb_results[3], \"XGBoost\")\n",
    "\n",
    "if cbt_results:\n",
    "    plot_confusion_matrix(cbt_results[2], cbt_results[3], \"CatBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roc_curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred_proba, model_name):\n",
    "    if y_pred_proba is None:\n",
    "        print(f\"ROC curve not available for {model_name} (no probability predictions)\")\n",
    "        return\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred_proba)\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f\"{model_name} (AUC = {auc:.4f})\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", linewidth=2, label=\"Random Classifier\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve - {model_name}\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curves for all models\n",
    "for name, (model, results) in baseline_results.items():\n",
    "    y_train, train_pred, y_test, test_pred, _, test_pred_proba = results\n",
    "    plot_roc_curve(y_test, test_pred_proba, name)\n",
    "\n",
    "if rf_results:\n",
    "    plot_roc_curve(rf_results[2], rf_results[5], \"Random Forest\")\n",
    "\n",
    "if lgb_results:\n",
    "    plot_roc_curve(lgb_results[2], lgb_results[5], \"LightGBM\")\n",
    "\n",
    "if xgb_results:\n",
    "    plot_roc_curve(xgb_results[2], xgb_results[5], \"XGBoost\")\n",
    "\n",
    "if cbt_results:\n",
    "    plot_roc_curve(cbt_results[2], cbt_results[5], \"CatBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "all_roc_curves",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all ROC curves on one plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for name, (model, results) in baseline_results.items():\n",
    "    y_train, train_pred, y_test, test_pred, _, test_pred_proba = results\n",
    "    if test_pred_proba is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, test_pred_proba)\n",
    "        auc = roc_auc_score(y_test, test_pred_proba)\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=f\"{name} (AUC = {auc:.4f})\")\n",
    "\n",
    "if rf_results and rf_results[5] is not None:\n",
    "    fpr, tpr, _ = roc_curve(rf_results[2], rf_results[5])\n",
    "    auc = roc_auc_score(rf_results[2], rf_results[5])\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f\"Random Forest (AUC = {auc:.4f})\")\n",
    "\n",
    "if lgb_results and lgb_results[5] is not None:\n",
    "    fpr, tpr, _ = roc_curve(lgb_results[2], lgb_results[5])\n",
    "    auc = roc_auc_score(lgb_results[2], lgb_results[5])\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f\"LightGBM (AUC = {auc:.4f})\")\n",
    "\n",
    "if xgb_results and xgb_results[5] is not None:\n",
    "    fpr, tpr, _ = roc_curve(xgb_results[2], xgb_results[5])\n",
    "    auc = roc_auc_score(xgb_results[2], xgb_results[5])\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f\"XGBoost (AUC = {auc:.4f})\")\n",
    "\n",
    "if cbt_results and cbt_results[5] is not None:\n",
    "    fpr, tpr, _ = roc_curve(cbt_results[2], cbt_results[5])\n",
    "    auc = roc_auc_score(cbt_results[2], cbt_results[5])\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f\"CatBoost (AUC = {auc:.4f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], \"k--\", linewidth=2, label=\"Random Classifier\")\n",
    "plt.xlabel(\"False Positive Rate\", fontsize=12)\n",
    "plt.ylabel(\"True Positive Rate\", fontsize=12)\n",
    "plt.title(\"ROC Curves - All Models\", fontsize=14)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb4ab6",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c00b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, X_df, model_name, top_n=20):\n",
    "    if hasattr(model, \"feature_importances_\"):\n",
    "        importances = model.feature_importances_\n",
    "    elif hasattr(model, \"feature_importance\"):\n",
    "        importances = model.feature_importance()\n",
    "    elif hasattr(model, \"coef_\"):\n",
    "        importances = np.abs(model.coef_[0])\n",
    "    else:\n",
    "        print(f\"Feature importance not available for {model_name}\")\n",
    "        return\n",
    "\n",
    "    feature_imp = pd.DataFrame({\n",
    "        \"feature\": X_df.columns,\n",
    "        \"importance\": importances\n",
    "    }).sort_values(\"importance\", ascending=False).head(top_n)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=feature_imp, palette=\"viridis\")\n",
    "    plt.title(f\"Top {top_n} Feature Importances - {model_name}\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot feature importance for models that support it\n",
    "for name, (model, results) in baseline_results.items():\n",
    "    plot_feature_importance(model, X_train, name)\n",
    "\n",
    "plot_feature_importance(rf_trained, X_train, \"Random Forest\")\n",
    "\n",
    "if lgb_trained is not None:\n",
    "    plot_feature_importance(lgb_trained, X_train, \"LightGBM\")\n",
    "\n",
    "if xgb_trained is not None:\n",
    "    plot_feature_importance(xgb_trained, X_train, \"XGBoost\")\n",
    "\n",
    "if cbt_trained is not None:\n",
    "    plot_feature_importance(cbt_trained, X_train, \"CatBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf053b4",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690c02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(model, param_grid, X_train, y_train, model_name):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"f1\",\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters for {model_name}:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(f\"Best F1 Score: {grid_search.best_score_:.4f}\\n\")\n",
    "    return grid_search.best_estimator_\n",
    "\n",
    "# Random Forest tuning\n",
    "rf_param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "}\n",
    "rf_tuned = tune_hyperparameters(\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    \"Random Forest\",\n",
    ")\n",
    "\n",
    "# LightGBM tuning\n",
    "if lgb is not None:\n",
    "    lgb_param_grid = {\n",
    "        \"num_leaves\": [31, 50],\n",
    "        \"learning_rate\": [0.01, 0.1],\n",
    "        \"n_estimators\": [100, 200],\n",
    "    }\n",
    "    lgb_tuned = tune_hyperparameters(\n",
    "        lgb.LGBMClassifier(random_state=42, n_jobs=-1, verbosity=-1),\n",
    "        lgb_param_grid,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        \"LightGBM\",\n",
    "    )\n",
    "else:\n",
    "    lgb_tuned = None\n",
    "\n",
    "# XGBoost tuning\n",
    "if xgb is not None:\n",
    "    xgb_param_grid = {\n",
    "        \"max_depth\": [3, 6, 9],\n",
    "        \"learning_rate\": [0.01, 0.1],\n",
    "        \"n_estimators\": [100, 200],\n",
    "    }\n",
    "    xgb_tuned = tune_hyperparameters(\n",
    "        xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='logloss'),\n",
    "        xgb_param_grid,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        \"XGBoost\",\n",
    "    )\n",
    "else:\n",
    "    xgb_tuned = None\n",
    "\n",
    "# CatBoost tuning\n",
    "if cbt is not None:\n",
    "    cbt_param_grid = {\n",
    "        \"depth\": [6, 8],\n",
    "        \"learning_rate\": [0.01, 0.1],\n",
    "        \"iterations\": [100, 200],\n",
    "    }\n",
    "    cbt_tuned = tune_hyperparameters(\n",
    "        cbt.CatBoostClassifier(random_state=42, verbose=False),\n",
    "        cbt_param_grid,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        \"CatBoost\",\n",
    "    )\n",
    "else:\n",
    "    cbt_tuned = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cea91a8",
   "metadata": {},
   "source": [
    "## Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ca7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Model Evaluation with Tuned Hyperparameters:\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rf_final, rf_final_results = train_and_evaluate(\n",
    "    rf_tuned, X_train, y_train, X_test, y_test, \"Random Forest (Tuned)\"\n",
    ")\n",
    "\n",
    "if lgb_tuned is not None:\n",
    "    lgb_final, lgb_final_results = train_and_evaluate(\n",
    "        lgb_tuned, X_train, y_train, X_test, y_test, \"LightGBM (Tuned)\"\n",
    "    )\n",
    "else:\n",
    "    lgb_final, lgb_final_results = None, None\n",
    "\n",
    "if xgb_tuned is not None:\n",
    "    xgb_final, xgb_final_results = train_and_evaluate(\n",
    "        xgb_tuned, X_train, y_train, X_test, y_test, \"XGBoost (Tuned)\"\n",
    "    )\n",
    "else:\n",
    "    xgb_final, xgb_final_results = None, None\n",
    "\n",
    "if cbt_tuned is not None:\n",
    "    cbt_final, cbt_final_results = train_and_evaluate(\n",
    "        cbt_tuned, X_train, y_train, X_test, y_test, \"CatBoost (Tuned)\"\n",
    "    )\n",
    "else:\n",
    "    cbt_final, cbt_final_results = None, None\n",
    "\n",
    "# Plots for tuned models\n",
    "plot_confusion_matrix(rf_final_results[2], rf_final_results[3], \"Random Forest (Tuned)\")\n",
    "plot_roc_curve(rf_final_results[2], rf_final_results[5], \"Random Forest (Tuned)\")\n",
    "\n",
    "if lgb_final_results is not None:\n",
    "    plot_confusion_matrix(lgb_final_results[2], lgb_final_results[3], \"LightGBM (Tuned)\")\n",
    "    plot_roc_curve(lgb_final_results[2], lgb_final_results[5], \"LightGBM (Tuned)\")\n",
    "\n",
    "if xgb_final_results is not None:\n",
    "    plot_confusion_matrix(xgb_final_results[2], xgb_final_results[3], \"XGBoost (Tuned)\")\n",
    "    plot_roc_curve(xgb_final_results[2], xgb_final_results[5], \"XGBoost (Tuned)\")\n",
    "\n",
    "if cbt_final_results is not None:\n",
    "    plot_confusion_matrix(cbt_final_results[2], cbt_final_results[3], \"CatBoost (Tuned)\")\n",
    "    plot_roc_curve(cbt_final_results[2], cbt_final_results[5], \"CatBoost (Tuned)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136fc972",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classification_report",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report for all models\n",
    "print(\"=\"*80)\n",
    "print(\"CLASSIFICATION REPORTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, (model, results) in baseline_results.items():\n",
    "    y_train, train_pred, y_test, test_pred, _, _ = results\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(y_test, test_pred, target_names=le_target.classes_))\n",
    "\n",
    "print(f\"\\nRandom Forest (Tuned):\")\n",
    "print(\"-\"*80)\n",
    "print(classification_report(rf_final_results[2], rf_final_results[3], target_names=le_target.classes_))\n",
    "\n",
    "if lgb_final_results is not None:\n",
    "    print(f\"\\nLightGBM (Tuned):\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(lgb_final_results[2], lgb_final_results[3], target_names=le_target.classes_))\n",
    "\n",
    "if xgb_final_results is not None:\n",
    "    print(f\"\\nXGBoost (Tuned):\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(xgb_final_results[2], xgb_final_results[3], target_names=le_target.classes_))\n",
    "\n",
    "if cbt_final_results is not None:\n",
    "    print(f\"\\nCatBoost (Tuned):\")\n",
    "    print(\"-\"*80)\n",
    "    print(classification_report(cbt_final_results[2], cbt_final_results[3], target_names=le_target.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd01522",
   "metadata": {},
   "source": [
    "## Model Comparison and Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0dd1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_summary(y_true, y_pred, y_pred_proba, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    else:\n",
    "        auc = None\n",
    "    \n",
    "    return {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC-ROC\": auc,\n",
    "    }\n",
    "\n",
    "model_results = []\n",
    "\n",
    "for name, (model, results) in baseline_results.items():\n",
    "    y_train, train_pred, y_test, test_pred, _, test_pred_proba = results\n",
    "    model_results.append(evaluate_model_summary(y_test, test_pred, test_pred_proba, name))\n",
    "\n",
    "model_results.append(\n",
    "    evaluate_model_summary(\n",
    "        rf_final_results[2], rf_final_results[3], rf_final_results[5], \"Random Forest (Tuned)\"\n",
    "    )\n",
    ")\n",
    "\n",
    "if lgb_final_results is not None:\n",
    "    model_results.append(\n",
    "        evaluate_model_summary(\n",
    "            lgb_final_results[2], lgb_final_results[3], lgb_final_results[5], \"LightGBM (Tuned)\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "if xgb_final_results is not None:\n",
    "    model_results.append(\n",
    "        evaluate_model_summary(\n",
    "            xgb_final_results[2], xgb_final_results[3], xgb_final_results[5], \"XGBoost (Tuned)\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "if cbt_final_results is not None:\n",
    "    model_results.append(\n",
    "        evaluate_model_summary(\n",
    "            cbt_final_results[2], cbt_final_results[3], cbt_final_results[5], \"CatBoost (Tuned)\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(model_results).sort_values(\"F1 Score\", ascending=False)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "best_model_row = results_df.iloc[0]\n",
    "best_model_name = best_model_row[\"Model\"]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST PERFORMING MODEL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_model_row['Accuracy']:.4f}\")\n",
    "print(f\"Precision: {best_model_row['Precision']:.4f}\")\n",
    "print(f\"Recall: {best_model_row['Recall']:.4f}\")\n",
    "print(f\"F1 Score: {best_model_row['F1 Score']:.4f}\")\n",
    "if best_model_row['AUC-ROC'] is not None:\n",
    "    print(f\"AUC-ROC: {best_model_row['AUC-ROC']:.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Accuracy comparison\n",
    "sns.barplot(x=\"Model\", y=\"Accuracy\", data=results_df, ax=axes[0, 0], palette=\"Blues_d\")\n",
    "axes[0, 0].set_title(\"Model Accuracy Comparison\", fontsize=14)\n",
    "axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "axes[0, 0].set_ylim([0.7, 1.0])\n",
    "\n",
    "# Precision comparison\n",
    "sns.barplot(x=\"Model\", y=\"Precision\", data=results_df, ax=axes[0, 1], palette=\"Greens_d\")\n",
    "axes[0, 1].set_title(\"Model Precision Comparison\", fontsize=14)\n",
    "axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "axes[0, 1].set_ylim([0.5, 1.0])\n",
    "\n",
    "# F1 Score comparison\n",
    "sns.barplot(x=\"Model\", y=\"F1 Score\", data=results_df, ax=axes[1, 0], palette=\"Oranges_d\")\n",
    "axes[1, 0].set_title(\"Model F1 Score Comparison\", fontsize=14)\n",
    "axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "axes[1, 0].set_ylim([0.5, 1.0])\n",
    "\n",
    "# AUC-ROC comparison\n",
    "results_df_with_auc = results_df[results_df['AUC-ROC'].notna()]\n",
    "if len(results_df_with_auc) > 0:\n",
    "    sns.barplot(x=\"Model\", y=\"AUC-ROC\", data=results_df_with_auc, ax=axes[1, 1], palette=\"Purples_d\")\n",
    "    axes[1, 1].set_title(\"Model AUC-ROC Comparison\", fontsize=14)\n",
    "    axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45, ha=\"right\")\n",
    "    axes[1, 1].set_ylim([0.7, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2be2348",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Summary of the pipeline:**\n",
    "1. Performed EDA to understand the distribution of features and the target variable (income).\n",
    "2. Preprocessed data by handling missing values (including '?' placeholders), filling with median/mode, and label encoding categorical features.\n",
    "   > In production, consider one-hot encoding for better performance with linear models.\n",
    "3. Split data into training (80%) and testing (20%) sets with stratification to preserve class balance.\n",
    "4. Trained baseline models (Logistic Regression, Naive Bayes) and advanced tree-based models (Random Forest, LightGBM, XGBoost, CatBoost).\n",
    "5. Evaluated models using classification metrics: accuracy, precision, recall, F1 score, and AUC-ROC.\n",
    "6. Visualized performance through confusion matrices and ROC curves.\n",
    "7. Analyzed feature importance to understand key predictors of income.\n",
    "8. Tuned hyperparameters using GridSearchCV to optimize F1 score.\n",
    "9. Compared all models and identified the best performer.\n",
    "\n",
    "**Key Insights:**\n",
    "- The Adult dataset shows class imbalance with more <=50K instances than >50K.\n",
    "- Features like education, age, occupation, marital status, and hours per week are strong predictors of income.\n",
    "- Tree-based ensemble models (Random Forest, XGBoost, LightGBM, CatBoost) generally outperform baseline models.\n",
    "- Hyperparameter tuning can significantly improve model performance, especially for complex models.\n",
    "- The '?' values in the dataset represent missing data and were handled during preprocessing.\n",
    "\n",
    "**Next steps / enhancements:**\n",
    "- Feature engineering: create interaction features, bin continuous variables, combine related categories.\n",
    "- Handle class imbalance using SMOTE, class weights, or threshold adjustment.\n",
    "- Use one-hot encoding instead of label encoding for categorical features to improve linear model performance.\n",
    "- Try stacking/blending ensembles for improved performance.\n",
    "- Use SHAP values for better model explainability and understanding feature contributions.\n",
    "- Perform cross-validation for more robust evaluation.\n",
    "- Try more advanced hyperparameter optimization techniques (Bayesian optimization, Optuna).\n",
    "- Analyze misclassified instances to understand model weaknesses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
